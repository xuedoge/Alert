time（时间，每十秒写入一次记录） ApiId Average（所有访问平均响应时间） CallCount（调用次数） 
E4XXCallCount E5XXCallCount ErrorRate 
S1000CallCount S100CallCount S3000CallCount S5000CallCount SLongCallCount 
ToServer TotalSpend（总共耗时）

思路：
    E4XX E5XX ErrorRate 表示错误情况
    S100-S5000 表示相应时间

    以上两个维度，每分钟生成一个数据点。
    使用sos算法可以聚类出每个点是异常点的概率。
    那需要的数据是什么？（使用前一个小时的数据，来判断最近五分钟的数据点是否是异常点。）


有些问题：

    1.数据存在规律性，每天的不同时间段可能出现的峰值不同，数据按天，周呈现周期。甚至按月份，年有不同的周期性变化。这些问题要怎么考虑。
    节假日时，数据肯定会有剧烈变化，肯定会产生异常点，这些怎么考虑。如果忽视这些规律性的话，管理者可能每天固定时间收到警告，或者每周固定某一天有很多警告。
    这些警报很明显是误报，因为这段时间就应该和平时不一样。

    2.如果使用前一个小时的数据，来判断最近五分钟的数据点是否是异常点，每次抢购都会出现异常点。（好像逻辑没有问题）（这里应该不必要考虑这么复杂）
    五分钟一个数据点，一个小时12个数据点。当一个点和其它所有点的关联度（affinity）都很小的时候，它就是一个异常点。
    根据时间规律，访问量，响应时间，错误率可能是递增的或者是递减的。在十二个数据点中，递增的峰值点并没有很高的概率成为异常点。
    递增幅度过大，距离原先的点过于远，就会成为异常点。
    但如果错误率或响应时间持续递增，增长到了很高的地方，很明显出现异常，但因为周围一直是异常，所以不会报警。


    3.sos算法，如果需要准确性，数据至少需要一天的点。
    因为数据点会根据时间发生变化。每天的不同时间段，数据点的分布不同。
    所以，用多久的数据，会极大影响准确性。用的数据越多，准确率越高，效率越低。
    需要找到一个平衡点。可以先用一些数据跑一下看效率。